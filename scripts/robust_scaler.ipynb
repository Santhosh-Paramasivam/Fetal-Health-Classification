{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from performance_measures import performance_measures\n",
    "import timeit\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FetalHealth = pd.read_csv(r\"source\\fetal_health.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis consists of :\n",
    "\n",
    "1. Count plot\n",
    "2. Correlation heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing :\n",
    "\n",
    "1. Scaling\n",
    "2. X,y and test, train division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FetalHealth.drop(['fetal_health'], axis = 1)\n",
    "y = FetalHealth['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline value</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>1.069490e-15</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-2.775197</td>\n",
       "      <td>-0.742373</td>\n",
       "      <td>-0.030884</td>\n",
       "      <td>0.680604</td>\n",
       "      <td>2.713428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-4.010589e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.822388</td>\n",
       "      <td>-0.822388</td>\n",
       "      <td>-0.304881</td>\n",
       "      <td>0.730133</td>\n",
       "      <td>4.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetal_movement</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-1.336863e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.203210</td>\n",
       "      <td>-0.203210</td>\n",
       "      <td>-0.203210</td>\n",
       "      <td>-0.138908</td>\n",
       "      <td>10.106540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uterine_contractions</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-1.336863e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-1.482465</td>\n",
       "      <td>-0.803434</td>\n",
       "      <td>-0.124404</td>\n",
       "      <td>0.894142</td>\n",
       "      <td>3.610264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light_decelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-5.347452e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.638438</td>\n",
       "      <td>-0.638438</td>\n",
       "      <td>-0.638438</td>\n",
       "      <td>0.375243</td>\n",
       "      <td>4.429965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_decelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>6.684315e-18</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.057476</td>\n",
       "      <td>-0.057476</td>\n",
       "      <td>-0.057476</td>\n",
       "      <td>-0.057476</td>\n",
       "      <td>17.398686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>1.336863e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.268754</td>\n",
       "      <td>-0.268754</td>\n",
       "      <td>-0.268754</td>\n",
       "      <td>-0.268754</td>\n",
       "      <td>8.208570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-7.352747e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-2.035639</td>\n",
       "      <td>-0.872088</td>\n",
       "      <td>0.116930</td>\n",
       "      <td>0.815060</td>\n",
       "      <td>2.327675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>6.684315e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-1.282833</td>\n",
       "      <td>-0.716603</td>\n",
       "      <td>-0.150373</td>\n",
       "      <td>0.415857</td>\n",
       "      <td>6.417893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-5.347452e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.535361</td>\n",
       "      <td>-0.535361</td>\n",
       "      <td>-0.535361</td>\n",
       "      <td>0.062707</td>\n",
       "      <td>4.412293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>2.406354e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-1.455081</td>\n",
       "      <td>-0.637583</td>\n",
       "      <td>-0.139975</td>\n",
       "      <td>0.464263</td>\n",
       "      <td>7.555172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_width</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-3.007942e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-1.731757</td>\n",
       "      <td>-0.858765</td>\n",
       "      <td>-0.075640</td>\n",
       "      <td>0.758838</td>\n",
       "      <td>2.812936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_min</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-4.679021e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-1.474609</td>\n",
       "      <td>-0.899376</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>0.893996</td>\n",
       "      <td>2.213648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_max</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-1.203177e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-2.342558</td>\n",
       "      <td>-0.670314</td>\n",
       "      <td>-0.112899</td>\n",
       "      <td>0.555999</td>\n",
       "      <td>4.123453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-1.671079e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-1.379664</td>\n",
       "      <td>-0.701397</td>\n",
       "      <td>-0.362263</td>\n",
       "      <td>0.655137</td>\n",
       "      <td>4.724738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>2.757280e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>-0.458444</td>\n",
       "      <td>13.708003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_mode</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>1.069490e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-4.729191</td>\n",
       "      <td>-0.516077</td>\n",
       "      <td>0.094519</td>\n",
       "      <td>0.644055</td>\n",
       "      <td>3.025381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_mean</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-6.684315e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-3.951945</td>\n",
       "      <td>-0.616458</td>\n",
       "      <td>0.089126</td>\n",
       "      <td>0.666422</td>\n",
       "      <td>3.039749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_median</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>2.673726e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-4.223849</td>\n",
       "      <td>-0.628514</td>\n",
       "      <td>0.062897</td>\n",
       "      <td>0.685166</td>\n",
       "      <td>3.312527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_variance</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-5.347452e-17</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-0.649208</td>\n",
       "      <td>-0.580173</td>\n",
       "      <td>-0.407586</td>\n",
       "      <td>0.179212</td>\n",
       "      <td>8.635997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histogram_tendency</th>\n",
       "      <td>2126.0</td>\n",
       "      <td>-1.069490e-16</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>-2.162031</td>\n",
       "      <td>-0.524526</td>\n",
       "      <td>-0.524526</td>\n",
       "      <td>1.112980</td>\n",
       "      <td>1.112980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     count          mean  \\\n",
       "baseline value                                      2126.0  1.069490e-15   \n",
       "accelerations                                       2126.0 -4.010589e-17   \n",
       "fetal_movement                                      2126.0 -1.336863e-17   \n",
       "uterine_contractions                                2126.0 -1.336863e-16   \n",
       "light_decelerations                                 2126.0 -5.347452e-17   \n",
       "severe_decelerations                                2126.0  6.684315e-18   \n",
       "prolongued_decelerations                            2126.0  1.336863e-17   \n",
       "abnormal_short_term_variability                     2126.0 -7.352747e-17   \n",
       "mean_value_of_short_term_variability                2126.0  6.684315e-17   \n",
       "percentage_of_time_with_abnormal_long_term_vari...  2126.0 -5.347452e-17   \n",
       "mean_value_of_long_term_variability                 2126.0  2.406354e-16   \n",
       "histogram_width                                     2126.0 -3.007942e-17   \n",
       "histogram_min                                       2126.0 -4.679021e-17   \n",
       "histogram_max                                       2126.0 -1.203177e-16   \n",
       "histogram_number_of_peaks                           2126.0 -1.671079e-16   \n",
       "histogram_number_of_zeroes                          2126.0  2.757280e-17   \n",
       "histogram_mode                                      2126.0  1.069490e-16   \n",
       "histogram_mean                                      2126.0 -6.684315e-16   \n",
       "histogram_median                                    2126.0  2.673726e-16   \n",
       "histogram_variance                                  2126.0 -5.347452e-17   \n",
       "histogram_tendency                                  2126.0 -1.069490e-16   \n",
       "\n",
       "                                                         std       min  \\\n",
       "baseline value                                      1.000235 -2.775197   \n",
       "accelerations                                       1.000235 -0.822388   \n",
       "fetal_movement                                      1.000235 -0.203210   \n",
       "uterine_contractions                                1.000235 -1.482465   \n",
       "light_decelerations                                 1.000235 -0.638438   \n",
       "severe_decelerations                                1.000235 -0.057476   \n",
       "prolongued_decelerations                            1.000235 -0.268754   \n",
       "abnormal_short_term_variability                     1.000235 -2.035639   \n",
       "mean_value_of_short_term_variability                1.000235 -1.282833   \n",
       "percentage_of_time_with_abnormal_long_term_vari...  1.000235 -0.535361   \n",
       "mean_value_of_long_term_variability                 1.000235 -1.455081   \n",
       "histogram_width                                     1.000235 -1.731757   \n",
       "histogram_min                                       1.000235 -1.474609   \n",
       "histogram_max                                       1.000235 -2.342558   \n",
       "histogram_number_of_peaks                           1.000235 -1.379664   \n",
       "histogram_number_of_zeroes                          1.000235 -0.458444   \n",
       "histogram_mode                                      1.000235 -4.729191   \n",
       "histogram_mean                                      1.000235 -3.951945   \n",
       "histogram_median                                    1.000235 -4.223849   \n",
       "histogram_variance                                  1.000235 -0.649208   \n",
       "histogram_tendency                                  1.000235 -2.162031   \n",
       "\n",
       "                                                         25%       50%  \\\n",
       "baseline value                                     -0.742373 -0.030884   \n",
       "accelerations                                      -0.822388 -0.304881   \n",
       "fetal_movement                                     -0.203210 -0.203210   \n",
       "uterine_contractions                               -0.803434 -0.124404   \n",
       "light_decelerations                                -0.638438 -0.638438   \n",
       "severe_decelerations                               -0.057476 -0.057476   \n",
       "prolongued_decelerations                           -0.268754 -0.268754   \n",
       "abnormal_short_term_variability                    -0.872088  0.116930   \n",
       "mean_value_of_short_term_variability               -0.716603 -0.150373   \n",
       "percentage_of_time_with_abnormal_long_term_vari... -0.535361 -0.535361   \n",
       "mean_value_of_long_term_variability                -0.637583 -0.139975   \n",
       "histogram_width                                    -0.858765 -0.075640   \n",
       "histogram_min                                      -0.899376 -0.019608   \n",
       "histogram_max                                      -0.670314 -0.112899   \n",
       "histogram_number_of_peaks                          -0.701397 -0.362263   \n",
       "histogram_number_of_zeroes                         -0.458444 -0.458444   \n",
       "histogram_mode                                     -0.516077  0.094519   \n",
       "histogram_mean                                     -0.616458  0.089126   \n",
       "histogram_median                                   -0.628514  0.062897   \n",
       "histogram_variance                                 -0.580173 -0.407586   \n",
       "histogram_tendency                                 -0.524526 -0.524526   \n",
       "\n",
       "                                                         75%        max  \n",
       "baseline value                                      0.680604   2.713428  \n",
       "accelerations                                       0.730133   4.093929  \n",
       "fetal_movement                                     -0.138908  10.106540  \n",
       "uterine_contractions                                0.894142   3.610264  \n",
       "light_decelerations                                 0.375243   4.429965  \n",
       "severe_decelerations                               -0.057476  17.398686  \n",
       "prolongued_decelerations                           -0.268754   8.208570  \n",
       "abnormal_short_term_variability                     0.815060   2.327675  \n",
       "mean_value_of_short_term_variability                0.415857   6.417893  \n",
       "percentage_of_time_with_abnormal_long_term_vari...  0.062707   4.412293  \n",
       "mean_value_of_long_term_variability                 0.464263   7.555172  \n",
       "histogram_width                                     0.758838   2.812936  \n",
       "histogram_min                                       0.893996   2.213648  \n",
       "histogram_max                                       0.555999   4.123453  \n",
       "histogram_number_of_peaks                           0.655137   4.724738  \n",
       "histogram_number_of_zeroes                         -0.458444  13.708003  \n",
       "histogram_mode                                      0.644055   3.025381  \n",
       "histogram_mean                                      0.666422   3.039749  \n",
       "histogram_median                                    0.685166   3.312527  \n",
       "histogram_variance                                  0.179212   8.635997  \n",
       "histogram_tendency                                  1.112980   1.112980  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = list(X.columns)\n",
    "# Three different scaling methods\n",
    "\n",
    "#s_scaler = preprocessing.StandardScaler()\n",
    "#s_scaler = preprocessing.MinMaxScaler()\n",
    "s_scaler = preprocessing.RobustScaler()\n",
    "#s_scaler = preprocessing.MaxAbsScaler()\n",
    "#s_scaler = preprocessing.Normalizer()\n",
    "#s_scaler = preprocessing.QuantileTransformer()\n",
    "\n",
    "scaler_name = \"Robust Scaler\"\n",
    "noscale = False\n",
    "if(noscale):\n",
    "    X_df = X\n",
    "else:\n",
    "    X_df= s_scaler.fit_transform(X)\n",
    "\n",
    "X_df = pd.DataFrame(X_df, columns=col_names)   \n",
    "X_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X_df,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train,y_train = ros.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceMeasuresDF = pd.DataFrame(columns=['Classifier Model', 'Accuracy','F1-Score','Recall','Precision','Jaccard-Score','Kappa-Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 ms ± 10.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Logistic Regression : \n",
      "Accuracy : 0.829153605015674\n",
      "F1 : 0.8444897352804529\n",
      "Recall : 0.829153605015674\n",
      "Precision : 0.8815067739511789\n",
      "Jaccard : 0.7458678319168522\n",
      "Kappa : 0.613055792033207\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 100000)\n",
    "result = %timeit -o -n 5 -r 5 lr.fit(X=X_train, y=y_train) \n",
    "lr.fit(X = X_train, y = y_train)\n",
    "measures = performance_measures(\"Logistic Regression\", lr, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time = result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614 ms ± 49.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "SVM Linear : \n",
      "Accuracy : 0.8275862068965517\n",
      "F1 : 0.8422017413975481\n",
      "Recall : 0.8275862068965517\n",
      "Precision : 0.8758525503219734\n",
      "Jaccard : 0.7419029578083128\n",
      "Kappa : 0.6044436678859887\n"
     ]
    }
   ],
   "source": [
    "svmlinear = SVC(kernel = 'linear')\n",
    "result = %timeit -o -n 5 -r 5 svmlinear.fit(X=X_train, y = y_train)\n",
    "svmlinear.fit(X=X_train, y = y_train)\n",
    "measures = performance_measures(\"Support Vector Machine(Linear)\", svmlinear, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561 ms ± 241 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "SVM RBF : \n",
      "Accuracy : 0.8667711598746082\n",
      "F1 : 0.8768344274947355\n",
      "Recall : 0.8667711598746082\n",
      "Precision : 0.9039672986490344\n",
      "Jaccard : 0.7899066397764395\n",
      "Kappa : 0.688969694188901\n"
     ]
    }
   ],
   "source": [
    "svmrbf = SVC(kernel = 'rbf')\n",
    "result = %timeit -o -n 5 -r 5 svmrbf.fit(X=X_train, y = y_train)\n",
    "svmrbf.fit(X=X_train, y = y_train)\n",
    "measures = performance_measures(\"Support Vector Machine(RBF)\", svmrbf, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two variants which haven't been tried before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.59 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "865 ms ± 639 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "SVM Poly : \n",
      "Accuracy : 0.8573667711598746\n",
      "F1 : 0.8667069617363671\n",
      "Recall : 0.8573667711598746\n",
      "Precision : 0.8870851445554866\n",
      "Jaccard : 0.7765662062274762\n",
      "Kappa : 0.6574668428753481\n"
     ]
    }
   ],
   "source": [
    "svmpoly = SVC(kernel = 'poly')\n",
    "result = %timeit -o -n 5 -r 5 svmpoly.fit(X=X_train, y = y_train)\n",
    "svmpoly.fit(X=X_train, y = y_train)\n",
    "measures = performance_measures(\"Support Vector Machine(Poly)\",svmpoly, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810 ms ± 237 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "SVM Sigmoid : \n",
      "Accuracy : 0.6520376175548589\n",
      "F1 : 0.7068440350281284\n",
      "Recall : 0.6520376175548589\n",
      "Precision : 0.8459066400633176\n",
      "Jaccard : 0.5585236266514508\n",
      "Kappa : 0.37212797177067214\n"
     ]
    }
   ],
   "source": [
    "svmsigmoid = SVC(kernel = 'sigmoid')\n",
    "result = %timeit -o -n 5 -r 5 svmsigmoid.fit(X=X_train, y = y_train)\n",
    "svmsigmoid.fit(X=X_train, y = y_train)\n",
    "measures = performance_measures(\"Support Vector Machine(Sigmoid)\",svmsigmoid, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.64 ms ± 3.23 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "K-Nearest Neighbors : \n",
      "Accuracy : 0.85423197492163\n",
      "F1 : 0.8646910717286094\n",
      "Recall : 0.85423197492163\n",
      "Precision : 0.8872843890423953\n",
      "Jaccard : 0.7749695896500054\n",
      "Kappa : 0.652735264337678\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "result = %timeit -o -n 5 -r 5 knn.fit(X=X_train, y = y_train) \n",
    "knn.fit(X=X_train, y = y_train)\n",
    "measures = performance_measures(\"K-Nearest Neighbors\",knn, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 ms ± 1.3 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Naive Bayes : \n",
      "Accuracy : 0.6520376175548589\n",
      "F1 : 0.6906620704515873\n",
      "Recall : 0.6520376175548589\n",
      "Precision : 0.8521497798109492\n",
      "Jaccard : 0.5357928003380658\n",
      "Kappa : 0.3780829977913507\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "result = %timeit -o -n 5 -r 5 gnb.fit(X_train, y_train)\n",
    "gnb.fit(X_train, y_train)\n",
    "measures = performance_measures(\"Naive Bayes\",gnb, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.2 ms ± 9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Decision Trees : \n",
      "Accuracy : 0.9137931034482759\n",
      "F1 : 0.9133441502181755\n",
      "Recall : 0.9137931034482759\n",
      "Precision : 0.912962801041915\n",
      "Jaccard : 0.847234946433551\n",
      "Kappa : 0.7628429113077095\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "result = %timeit -o -n 5 -r 5 dt.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "measures = performance_measures(\"Decision Tree\",dt, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 ms ± 232 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Random Forest Classifier : \n",
      "Accuracy : 0.9357366771159875\n",
      "F1 : 0.9356363710608147\n",
      "Recall : 0.9357366771159875\n",
      "Precision : 0.9358424304461027\n",
      "Jaccard : 0.8839321095023362\n",
      "Kappa : 0.8253583565338728\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "result = %timeit -o -n 5 -r 5 rfc.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "measures = performance_measures(\"Random Forest\",rfc, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 ms ± 127 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Santhosh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Classifier : \n",
      "Accuracy : 0.8871473354231975\n",
      "F1 : 0.8922203194307323\n",
      "Recall : 0.8871473354231975\n",
      "Precision : 0.9037482268486758\n",
      "Jaccard : 0.8123084124727266\n",
      "Kappa : 0.7184448762189628\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(n_estimators = 100, random_state = 42)\n",
    "result = %timeit -o -n 5 -r 5 abc.fit(X_train, y_train)\n",
    "abc.fit(X_train, y_train)\n",
    "measures = performance_measures(\"Ada Boost\",abc, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13 s ± 673 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Gradient Boost Classifier : \n",
      "Accuracy : 0.8824451410658307\n",
      "F1 : 0.889478732362703\n",
      "Recall : 0.8824451410658307\n",
      "Precision : 0.9123061851569174\n",
      "Jaccard : 0.8067182439299724\n",
      "Kappa : 0.7229556034183284\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators = 100, random_state = 42, learning_rate = 1.0, max_depth = 1)\n",
    "result = %timeit -o -n 5 -r 5 gbc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "measures = performance_measures(\"Gradient Boost\",gbc, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842 ms ± 278 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Accuracy : 0.9545454545454546\n",
      "F1 : 0.9544474452495844\n",
      "Recall : 0.9545454545454546\n",
      "Precision : 0.954673114614897\n",
      "Jaccard : 0.9150425054580357\n",
      "Kappa : 0.8764729838898124\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder = False, eval_metric = 'mlogloss')\n",
    "result = %timeit -o -n 5 -r 5 xgb.fit(X_train, y_train - 1)\n",
    "xgb.fit(X_train, y_train - 1)\n",
    "measures = performance_measures(\"XG Boost\",xgb, X_test, y_test - 1, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "762 ms ± 192 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 3477, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy : 0.9561128526645768\n",
      "F1 : 0.9555792458398668\n",
      "Recall : 0.9561128526645768\n",
      "Precision : 0.9554740609172917\n",
      "Jaccard : 0.9172395981761186\n",
      "Kappa : 0.8783404614672151\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "result = %timeit -o -n 5 -r 5 lgbm.fit(X_train, y_train)\n",
    "lgbm.fit(X_train, y_train)\n",
    "measures = performance_measures(\"LightGBM\",lgbm, X_test, y_test, performanceMeasuresDF)\n",
    "performanceMeasuresDF.loc[len(performanceMeasuresDF)] = measures\n",
    "exec_time += result.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceMeasuresDF[\"Weighted_Score\"] = performanceMeasuresDF[\"Accuracy\"] + performanceMeasuresDF[\"F1-Score\"] + performanceMeasuresDF[\"Recall\"] + performanceMeasuresDF[\"Precision\"] + performanceMeasuresDF[\"Jaccard-Score\"] + performanceMeasuresDF[\"Kappa-Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceTable = performanceMeasuresDF.sort_values(by = \"Weighted_Score\",ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "performanceTable.to_excel(\"scripts/new_results/\"+ scaler_name + '.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.490542459421724\n"
     ]
    }
   ],
   "source": [
    "with open(r\"scripts/new_results/\" + scaler_name + r\" Timings.txt\", \"+a\") as file:\n",
    "    file.write(str(exec_time) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
